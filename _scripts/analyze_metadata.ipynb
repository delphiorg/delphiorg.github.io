{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a73d8c7-ed3c-47ab-933b-aedbf6b89be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading metadata.csv ---\n",
      "First 5 rows of the data:\n",
      "                                            filename  \\\n",
      "0                        2008-08-18-now-on-itunes.md   \n",
      "1                 2008-09-05-updated-delphi-logos.md   \n",
      "2                        2008-09-29-audio-quality.md   \n",
      "3  2008-10-28-live-twitting-the-keynotes-at-pdc20...   \n",
      "4         2008-11-06-revenge-of-delphi-robot-rage.md   \n",
      "\n",
      "                                   title                       date  \\\n",
      "0                          Now on iTunes  2008-08-18T15:43:14-06:00   \n",
      "1                   Updated Delphi Logos  2008-09-05T20:17:35-06:00   \n",
      "2                          Audio Quality  2008-09-29T10:24:28-06:00   \n",
      "3  Live Twitting the Keynotes at PDC2008  2008-10-28T10:36:59-06:00   \n",
      "4       The Revenge of Delphi Robot Rage  2008-11-06T14:54:51-07:00   \n",
      "\n",
      "        author categories  tags  tag_count  \n",
      "0  Jim McKeeth       News  News          1  \n",
      "1  Jim McKeeth       News  News          1  \n",
      "2  Jim McKeeth       News  News          1  \n",
      "3  Jim McKeeth       News  News          1  \n",
      "4  Jim McKeeth       News  News          1  \n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# --- 1. Load the Data ---\n",
    "print(\"--- Loading metadata.csv ---\")\n",
    "df = pd.read_csv('metadata.csv')\n",
    "print(\"First 5 rows of the data:\")\n",
    "print(df.head())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aac67ec8-c0ea-42b2-b7dd-49f9eca01b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analyzing Tags ---\n",
      "Top 40 least Used Tags:\n",
      "tags\n",
      "PAClient               1\n",
      "PAServer               1\n",
      "Tablets                1\n",
      "windows                1\n",
      "Anders Hejlsberg       1\n",
      "Csharp                 1\n",
      "Turbo Pascal           1\n",
      "databasegear           1\n",
      "delphi jobs            1\n",
      "jobs                   1\n",
      "wideorbit              1\n",
      "fulcrum                1\n",
      "roadmap                1\n",
      "videos                 1\n",
      "64-bit                 1\n",
      "Code Coverage          1\n",
      "Delphi Mocks           1\n",
      "DUnit                  1\n",
      "DUnitX                 1\n",
      "mock objects           1\n",
      "unit test              1\n",
      "unit testing           1\n",
      "compression            1\n",
      "GZIP                   1\n",
      "JSON                   1\n",
      "TIdCompressorZLib      1\n",
      "TRESTResponse          1\n",
      "LED Lights             1\n",
      "Niagara Falls          1\n",
      "compare                1\n",
      "discount               1\n",
      "kylix                  1\n",
      "jvcl                   1\n",
      "sourceforge            1\n",
      "parrot                 1\n",
      "quadricopter           1\n",
      "Collections            1\n",
      "Demo                   1\n",
      "Generic Collections    1\n",
      "TList                  1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Analyze Tags ---\n",
    "print(\"--- Analyzing Tags ---\")\n",
    "# Drop rows where tags are not specified (NaN) and ensure tags are strings\n",
    "tags_df = df.dropna(subset=['tags'])\n",
    "tags_df = tags_df[tags_df['tags'].str.len() > 0]\n",
    "# Split the tags string into a list of tags, then explode the list into separate rows\n",
    "tag_counts = tags_df['tags'].str.split(', ').explode().value_counts()\n",
    "print(\"Top 40 least Used Tags:\")\n",
    "print(tag_counts.tail(40))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b214e5f-f7b0-47d8-8d27-bdde49a4a5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analyzing Categories ---\n",
      "Category Counts:\n",
      "categories\n",
      "News    233\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Analyze Categories ---\n",
    "print(\"--- Analyzing Categories ---\")\n",
    "categories_df = df.dropna(subset=['categories'])\n",
    "categories_df = categories_df[categories_df['categories'].str.len() > 0]\n",
    "category_counts = categories_df['categories'].str.split(', ').explode().value_counts()\n",
    "print(\"Category Counts:\")\n",
    "print(category_counts)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bd2e84c-2fd8-4698-bab4-ddd11de7c347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Example: Renaming 'podcast' to 'Audio podCast' (In Memory) ---\n",
      "Found 63 posts with the 'podcast' tag.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Example: Renaming a Tag (In-memory) ---\n",
    "print(\"--- Example: Renaming 'podcast' to 'Audio podCast' (In Memory) ---\")\n",
    "# This is a non-destructive example. It shows which posts would be affected.\n",
    "posts_with_podcast_tag = df[df['tags'].str.contains(r'\\bpodcast\\b', na=False, regex=True)] # Use regex=True for word boundary\n",
    "print(f\"Found {len(posts_with_podcast_tag)} posts with the 'podcast' tag.\")\n",
    "# To actually replace the tag in the DataFrame (not in the files yet):\n",
    "# df_modified = df.copy() # Make a copy if you want to apply changes to a new DataFrame\n",
    "# df_modified['tags'] = df_modified['tags'].str.replace(r'\\bpodcast\\b', 'Audio podCast', regex=True, na=False)\n",
    "# print(\"After replacement (first 5 affected posts):\")\n",
    "# print(df_modified[df_modified['tags'].str.contains('Audio podCast', na=False)][['filename', 'tags']].head())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dfcd8a-cd42-4fb2-94b2-d2a45ce035f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Updating the Post Files (Conceptual) ---\n",
    "print(\"--- Updating Post Files (Conceptual) ---\")\n",
    "print(\"The following code is a non-executable example of how you would run a script to update the files.\")\n",
    "print(\"It is commented out for safety. You would run this part manually after verifying your changes\")\n",
    "print(\"in a Jupyter Notebook or similar environment, and after backing up your posts!\")\n",
    "    \n",
    "update_script_example = \"\"\"\n",
    "# import os\n",
    "# import re\n",
    "# \n",
    "# # IMPORTANT: BACKUP YOUR _posts DIRECTORY BEFORE RUNNING THIS!\n",
    "# \n",
    "# # This is the DataFrame with your desired changes\n",
    "# # For this example, we'll use the df_modified from the cell above, or your final 'df' after modifications\n",
    "# # For demonstration, let's assume 'df' has your final desired tags.\n",
    "# # final_df = df_modified if 'df_modified' in locals() else df\n",
    "# \n",
    "# # --- Configuration for the update ---\n",
    "# # Set this to True ONLY when you are ready to write changes to files\n",
    "# WRITE_CHANGES_TO_FILES = False \n",
    "# # ------------------------------------\n",
    "# \n",
    "# # Ensure the 'tags' column is treated as strings for consistent splitting\n",
    "# final_df['tags'] = final_df['tags'].astype(str).replace('nan', '')\n",
    "# \n",
    "# print(f\"Preparing to process {len(final_df)} posts for updates...\")\n",
    "# \n",
    "# for index, row in final_df.iterrows():\n",
    "#     filename = row['filename']\n",
    "#     post_path = os.path.join('_posts', filename)\n",
    "# \n",
    "#     if not os.path.exists(post_path):\n",
    "#         print(f\"WARNING: File not found: {post_path}. Skipping.\")\n",
    "#         continue\n",
    "# \n",
    "#     with open(post_path, 'r', encoding='utf-8') as f:\n",
    "#         content = f.read()\n",
    "# \n",
    "#     # Regex to find the front matter and the tags block within it\n",
    "#     # This regex is an example and might need to be adjusted based on your exact front matter structure\n",
    "#     # It looks for the start of the front matter (---), captures everything until 'tags:',\n",
    "#     # then captures the tags block (until the next key:value or end of front matter)\n",
    "#     # and finally captures the rest of the front matter until the closing ---.\n",
    "# \n",
    "#     # The tag block can be either a single line 'tags: tag1, tag2' or multi-line\n",
    "#     # This regex is an improvement for handling multi-line tags list more robustly.\n",
    "#     # It captures the part *before* tags, the tags block itself, and the part *after* tags.\n",
    "# \n",
    "#     # Prepare new tags YAML string\n",
    "#     new_tags_list = [tag.strip() for tag in row['tags'].split(',') if tag.strip()]\n",
    "#     new_tags_yaml_block = 'tags:\\n' + '\\n'.join([f'  - {tag}' for tag in new_tags_list]) if new_tags_list else ''\n",
    "# \n",
    "#     # Regex to find and replace the tags block in YAML front matter\n",
    "#     # It assumes tags block is defined as 'tags:' followed by list items or inline array\n",
    "#     # This might need fine-tuning for edge cases in your YAML front matter.\n",
    "#     # Group 1: Everything before the 'tags:' key\n",
    "#     # Group 2: The 'tags:' key itself (to preserve indentation of 'tags:')\n",
    "#     # Group 3: The old tags block (list items or inline array)\n",
    "#     # Group 4: Everything after the tags block until the end of front matter (---)\n",
    "#     # This regex is highly dependent on your YAML structure.\n",
    "# \n",
    "#     # More robust regex for tags block replacement:\n",
    "#     # Matches the front matter content between the --- delimiters\n",
    "#     front_matter_pattern = re.compile(r'(^---\\s*$\\n)(.*?)(^---\\s*$)', re.MULTILINE | re.DOTALL)\n",
    "#     front_matter_match = front_matter_pattern.search(content)\n",
    "# \n",
    "#     if front_matter_match:\n",
    "#         fm_start = front_matter_match.group(1) # '---' start\n",
    "#         fm_content = front_matter_match.group(2) # Content of front matter\n",
    "#         fm_end = front_matter_match.group(3) # '---' end\n",
    "# \n",
    "#         # Regex to find 'tags:' line and subsequent list items or inline array\n",
    "#         # This version tries to be more robust by matching until the next key or end of front matter content\n",
    "#         tags_block_pattern = re.compile(r'(^\\s*tags:)(.*?)(^\\s*\\w+:|\\n---)', re.MULTILINE | re.DOTALL)\n",
    "#         tags_block_match = tags_block_pattern.search(fm_content)\n",
    "# \n",
    "#         if tags_block_match:\n",
    "#             # Tags block found, replace it\n",
    "#             before_tags = fm_content[:tags_block_match.start(1)]\n",
    "#             after_tags = fm_content[tags_block_match.end(3) - (len(tags_block_match.group(3)) if tags_block_match.group(3).startswith('\\n') else 0):] # Adjust end to include the next key if matched\n",
    "#             if tags_block_match.group(3) and not tags_block_match.group(3).strip().startswith('---'):\n",
    "#                 after_tags = tags_block_match.group(3) + after_tags # Add the next key back\n",
    "# \n",
    "#             new_fm_content = before_tags.strip() + '\\n' + new_tags_yaml_block + '\\n' + after_tags.strip()\n",
    "# \n",
    "#         elif new_tags_list: # No tags block found, but new tags exist, so insert it before the closing --- of front matter\n",
    "#             # Find the last key:value pair in the front matter and insert after it\n",
    "#             last_key_pattern = re.compile(r'(^\\s*\\w+:\\s*.*?)(?:\\n---|\\n\\s*\\w+:)', re.MULTILINE | re.DOTALL)\n",
    "#             last_key_match = None\n",
    "#             for m in last_key_pattern.finditer(fm_content):\n",
    "#                 last_key_match = m\n",
    "# \n",
    "#             if last_key_match:\n",
    "#                 insert_point = last_key_match.end(0)\n",
    "#                 new_fm_content = fm_content[:insert_point].strip() + '\\n' + new_tags_yaml_block + '\\n' + fm_content[insert_point:].strip()\n",
    "#             else:\n",
    "#                 # Fallback: just append before the end of front matter\n",
    "#                 new_fm_content = fm_content.strip() + '\\n' + new_tags_yaml_block\n",
    "# \n",
    "#         else:\n",
    "#             # No tags block, and no new tags to add\n",
    "#             new_fm_content = fm_content\n",
    "# \n",
    "#         updated_content = fm_start + new_fm_content.strip() + '\\n' + fm_end\n",
    "# \n",
    "#         if WRITE_CHANGES_TO_FILES:\n",
    "#             with open(post_path, 'w', encoding='utf-8') as f:\n",
    "#                 f.write(updated_content)\n",
    "#             print(f\"Updated {filename}\")\n",
    "#         else:\n",
    "#             print(f\"Would update {filename} (WRITE_CHANGES_TO_FILES is False)\")\n",
    "#     else:\n",
    "#         print(f\"Could not find front matter in {filename}. Skipping.\")\n",
    "# \n",
    "# print(\"File update process complete (conceptual).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
